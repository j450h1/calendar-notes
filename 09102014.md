### Notes for Today

Today we continue on Coursera: Regression Model: Week 3: 2/3. Main topics for today:

* **Simulation of Multivariate Regression**: This section aims to demonstrate, through simulation, how interpretation of predictor coefficients can change drastically, at the absence (or presence) of other uncorrelated (or correlated) variables.

* **Diagnostics**: diagnostic tools one can use to see if the assumption of the linear model has been met, using what R provides (don't think the instructor did a good job here)

* [Multivariate Simulation Exercises]: Several examples were given here -- rather than documenting them by the book, I think it's more important to internalize these cases and know how to spot them in real problems.

	* ![alt text](https://github.com/robert8138/Calendar_Notes/blob/master/images/simulation_1.png)

		* X and group variable (t) are uncorrelated (i.e. You can't tell the group from x, vice versa)
		* X is related to Y linearly, regardless if we fix group (t)
		* Y is also related to Y
			* The treatment effect can be observed with or without X for group variable (i.e. both model has different intercepts depending on group)
		
		* **Takeaway**: This is the cleanest example. Since X & t are uncorrelated, we can consider each of them (disregarding the other), and the coefficient results would be the same when you held the other constant. In other word, you can project/regress on each individual predictor, and the coefficient would be the same as when you do multivariate regression (?)

	* ![alt text](https://github.com/robert8138/Calendar_Notes/blob/master/images/simulation_2.png)

		* X and group variable (t) are correlated (i.e. low x associated with blue, high x associated with red)
		* X is related to Y (linearly)
			* X is related to Y, without considering t
			* Even for each fix group, X is still related to Y!
		* Is the group variable related to Y?
			* In the absence of X, it seems like the treatment effect is huge. so YES
			* However, when adjusted for X (fixed x), the treatment effect is gone. so NO
		
		* **Takeaway*: In this example, the treatment effect changes from existing to none, depending on if we control for X. But X is always linearly associated with Y (including/excluding group). So Be aware if treatment effect is real! (i.e. Are you being overly optimistic? Have you control for everything else?)

	* ![alt text](https://github.com/robert8138/Calendar_Notes/blob/master/images/simulation_3.png)

		* X and group (t) are somewhat correlated (except the middle section)
		* X is related to Y, whether we fix or disregard group variable
		* Group is related to Y, but:
			* When don't control for X, red is higher than blue
			* When fixing X, blue is higher than red

		* **Takeaway**: In this example, X continue to be correlated with Y (regardless), and treatment group is also in effect, but the trend reverse when we control/not control for X. (Simpson Paradox?)

	* ![alt text](https://github.com/robert8138/Calendar_Notes/blob/master/images/simulation_4.png)

		* X and group (t) are almost uncorrelated
		* X is related to Y (regardless if we fix the group)
		* Group is related to Y, the trend is the same, but the order of treatment effect is much larger when we control for X.

		* **Takeaway**: Be aware of this case, we thought we don't have anything good (no treatment effect in the aggregate), when in reality if you control for X, you get a huge difference in treatment effect. We might be overly pessimistic in this scenario.


	* ![alt text](https://github.com/robert8138/Calendar_Notes/blob/master/images/simulation_5.png)

		* X and group (t) are almost uncorrelated
		* X correlated with Y?
			* When disregard group, no association
			* When fixing group, the association is strong but reverse in group
		* For group t with Y?
			* It seems like it's marginally better for red than blue
			* However, when fixing x, the trend would reverse from negative x to positive x.

Modeling multivariate relationships is difficult. Play around with simulations to see how the inclusion or exclusion of another variable can change analyses. The results of these analyses deal with the impact of variables on associations.

* [Diagnostic]

	* Talk about outliers, influencers, and high leverage points.
		* outlier is a vague term
		* Influencers are those that would affect the fit a lot when including/excluding the dataset (`dbeta` in R)
		* high leverage points are points whose x is far away from the norm. (`hatvalues` in R)
	* The instructor did a poor job in explaning the four diagnostic plot from R. I think _introduction in statistical learning_ prepared me much better at this section.


[Multivariate Simulation Exercises]: http://bcaffo.github.io/courses/07_RegressionModels/02_03_adjustment/#1 
[Diagnostic]: http://bcaffo.github.io/courses/07_RegressionModels/02_04_residuals_variation_diagnostics/#1