#### Doing Data Science: Chapter 7

By now, I am very certain that this book is more on the philosophical side than technical side, but those are good thinkings. The authors are also clearly know what the industry is doing, so the examples they gave feels more real life to me.

In this chapter in particular, we were introduced the concept of feature generation and feature selection.

* **Feature generation**: A brainstorming process that often relies on domain expertise. Find as many as predictors we can possibly think of, and
* **Feature selection**: Let the algorithms to do the selections, a nice [paper] was introduced, and it talks about the three methods of feature selection:
	* **Filters**: (like using p-value, R squared) to rank list the features and take the top K, say.
	* **Wrappers**: tries to find subset of features, of some fixed size. Two components:
		* selectin an algorithm: forward, backward, mixed
		* selection criteria: p-value, R-squared, AIC, BIC are all sensible
	* **Embedded**: Decision tree is a very good example of this.
		* I like the intuitive explanation of entropy: How mixed up the bag is.

##### This feels like one of those unneccessary documents and commits

[paper]: http://jmlr.org/papers/volume3/guyon03a/guyon03a.pdf