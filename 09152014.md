### Notes for Today

Today we continue on the journey of Coursera: Regression Model: Week 4: 1/2. The main topic is Generalized Linear Model, and I think Brian Caffo did a very poor job in explaining the concept. I found Andrew Ng's Machine Learning [lecture notes] on GLM much more enlightening.

* [Generalized linear model]: Involves three components
	* Response is modeled using an exponential family distribution
	* A systematic component via a linear predictor
	* A link function that connects the mean response to the linear predictor.
	It also briefly talk about how to fit GLM, using iterative moethod to solve normal equaltions, but I don't really understand that part.

* [GLM: Binary Outcome]: 
	* Use to model two outcomes (e.g. alive/dead, win/loss, success/failure ... etc)
	* Interpreting logistic regression (very important, and I always keep forgetting them). slide 8/16.
	* **Interpretation of odds is also nice:**
		 * Setting: If it comes up heads, you win X, if comes up tail, you lose Y.
		 * Interpretation: "How much should you be willing to pay for a p probability of winning a dollar?" 
		 * Setting 2: If it comes up heads, dealer gets X, if comes up tail, dealer gives out Y
		 * Interpretation 2: "How much does the dealer needs to pay out for a p probability of winning based on a dollar of other player's entrance fee?". So 10:1 means that the dealer will have you give you 10x of what you put in if you win!
	* ANOVA for logistic regression is also good for comparing nested models.

[lecture notes]: http://cs229.stanford.edu/notes/cs229-notes1.pdf
[Generalized linear model]: http://bcaffo.github.io/courses/07_RegressionModels/03_01_glms/#1
[Binary Outcome]: http://bcaffo.github.io/courses/07_RegressionModels/03_02_binaryOutcomes/#1

---
To learn more about Tableau, you can visit the Tableau official website for more [videos](http://www.tableausoftware.com/learn/training)