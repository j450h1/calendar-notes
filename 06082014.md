### Notes for Today

## Coursera Data Science Series: "Reproducible Research"

* **Week 1 Materials**:
	* [**Reproducible Research**](https://d396qusza40orc.cloudfront.net/repdata/slides/ReproResearch.pdf):
		* The ultimate standard for strengthening scientific evidence is replication of findings and conducting studies with independent investigators, Data, Analytical methods, Laboratories, Instruments. But it's not always possible. So what's the second best that we can do? Reproducible Research: Make analytic data and code available so others may reproduce findings.

	* [**Structure of a Data Analysis I**](https://d396qusza40orc.cloudfront.net/repdata/slides/structureOfADataAnalysis1.pdf) & [**Structure of a Data Analysis II**](https://d396qusza40orc.cloudfront.net/repdata/slides/structureOfADataAnalysis2.pdf)
		* **Define the question**
		* **Define the ideal data set**
			The data set depends on your goal:
			* Descriptive - a whole population
			* Exploratory - a random sample with many variables measured
			* Inferential - the right population, randomly sampled
			* Predictive - A training and a test set from the same population
			* Causal - data from a randomized study
			* Mechanistic - data about all components of the system 
		* **Determine what data you can access**
		* **Obtain the data**
		* **Clean the data**
		* **Exploratory Data Analysis**
			* Look at summaries of the data
			* Check for missing data
			* Create exploratory plots
		* **Statistical Prediction/Modeling**
			* Should be informed by the results of your exploratory analysis
			* Transformation/processing should be accounted for when necessary
			* Measures of the uncertainty should be reported (e.g. accuracy in prediction model)
		* **Interpret Results**
			* Use the appropriate language
			* Give an explanation
			* Interpret coefficients
			* Interpret measures of uncertainty
		* **Challenge results**
			Others are bound to do it, so you might as well be ahead of the game
			* Challenge all steps: question, data source, processing, analysis, conclusion
			* Challenge measure of uncertainty
			* Challenge choice of terms in to include in the models
			* Think of potential alternative analyses
		* **Synthesize/write up results**
			* Lead with the question!
			* Summarize the analyses into a story
			* Don't include every analysis, include it when needed for the story, or to address a challenge
			* Order analyses according to the story, rather than chronologically
			* Inlcude pretty graphs
		* Create reproducible code

	* [**Organizing a Data Analysis**](https://d396qusza40orc.cloudfront.net/repdata/slides/organizingADataAnalysis.pdf): How you should set up your project folders (makes a lot of sense!)
		* **Data**
			* Raw data 
				* _If accessed from web, include url, description, and data accessed. Use git log to document this_
			* Processed data
				* _data should be tidy_
				* _The processing script should describe how we arrive at the processed data_
		* **Figures**
			* Exploratory figures
			* Final figures
		* **R code**
			* Raw / unused scripts
			* Final scripts
			* R Markdown files
		* **Text**
			* README files
				* _not necessary if you already have RMarkdown_
				* _Should contain step by step analysis_
			* Text of analysis / report
				* _It should tell a story_
				* _It should not include every analysis you performed_

* **Week 2 Materials**:

	* [**Coding Standards in R**](https://d396qusza40orc.cloudfront.net/repdata/slides/CodingStandard.pdf)
		* Always use text files/editor
		* Indent your code (4 space is minimum, 8 space is ideal in RStudio)
		* Limit the width of your code (80 columns). This prevents you from writing code that is overly nested
		* Limit the length of individual functions
			* Helpful for understanding the function definition in one shot
			* Good modularization and decomposition
			* Which in terms is very helpful when using debuggers or profilers

	* [**Introduction to Markdown**](): A simplified "markup" language that allow one to focus on writing opposed to formatting. Easily convert to HTML using existing tools. I am already using all these markdown syntax. 
		* Little trick: Use space space in the end of the line for a new line. 
	
	* [**R Markdown**](https://d396qusza40orc.cloudfront.net/repdata/slides/RMarkdown.pdf) 
		* R Markdown: is the integration of R code with markdown language. Allows one to create documents containing 'live' R codes. Results from R code are inserted into the markdown document.
		* Flow: The R markdown -> (using knitR) markdown -> (using markdown) HTML. RStudio has a good pipeline of doing all these. We can also create slides from these markdown using the package 'slidify'.
	
	* [**R Markdown Demo**]: No notes
	
	* [**Knitr**](https://d396qusza40orc.cloudfront.net/repdata/slides/knitr.pdf): Take notes for all 4 parts together
		* The whole point is that we want to do reproducible research
			* Literate programming is one way of acheiving this, by creating a article that is a stream of code and text. The idea of literate programming is to combine a documentation language with a programming language
				* Knitr is an R package that supports Markdown, LaTeX, and HTML as documentation language, and it use R as the programming language.
					* Good for: Manuals, short/medium-length technical documents. Tutorials. Reports, Data preprocessing documents.
					* Not Good for: Very long research articles, complex time consuming computations. Documents that require precise formatting.
				* Tricks around using knitr
					* code chinks being with ```{r} and end with ```
					* code chunks can have names, which is useful when start making grpahics
					* By default, code in a code chink is echoed, as will the results of the computation. This means they will be printed in the HTML output directly. However, you have the option of not echoeing the code and you have the option to hide the results. _```{r simulation, echo=FALSE, results="hide"}```_
					* You can also write inline text computations.
					* Graphics in Rmarkdown are standalone images that are directly embedded into HTML
					* Can use xtable to format the tables more nicely (say for a regression output)
					* Setting global options for code chunk can also be handy. _```{r setoptions, echo=FALSE} opts_chunk$set(echo = FALSE, results = "hide")```_
					* The cache=TRUE option allows you to cache computations.