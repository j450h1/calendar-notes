#### Introduction to dplyr

This package is written by the awesome Hadley Wickham, and it's mindblowing. The [github page] gives a quick premier of the package, but the [vignette] use flights data and really explained the core of the package well! Here is Hadley's own words on this package:

There are five functions that provide the basis of a language of data manipulation. At the most basic level, you can only alter a tidy data frame in five useful ways: 

* You can reorder the rows (`arrange()`)
* Pick observations and variables of interest (`filter()` and `select()`) 
* Add new variables that are functions of existing variables (`mutate()`) 
* Or collapse many values to a summary (`summarise()`). This is useful in conjunction with `group_by()`.

##### Filter
`filter()` allows you to select a subset of the rows of a data frame.
```{r}
filter(flights, month = 1, day = 1) # select observations/rows with date = 1/1

# is equivalent to the more verbose
flights[flights$month == 1 & flights$day == 1, ]
```

###### slice 
To select rows by position, using `slice`
```{r}
slice(flights, 1:10) #selects the first 10 rows
```

`filter()` works similarly to `subset()` except that you can give it any number of filtering conditions which are joined together with & (not && which is easy to do accidentally!).

##### Arrange

`arrange()` reorders rows. It takes a data frame, and a set of column names (or more complicated expressions) to order by.

```{r}
arrange(flights, year, month, day) # order the dataframe by year, then month, then day
arrange(flights, desc(arr_delay)) # order the dataframe by arr_delay in descending order

# is equivalent to the more verbose:
flights[order(flights$year, flights$month, flights$day), ]
flights[order(desc(flights$arr_delay)), ]
```
dplyr::arrange() works the same way as plyr::arrange(). It's a straighforward wrapper around order() that requires less typing.

##### Select
Often you work with large datasets with many columns where only a few are actually of interest to you. select() allows you to rapidly zoom in on a useful subset using operations that usually only work on numeric variable positions

```{r}
select(flights, year, month, day) # select columns by name
select(flights, year:day) # select all columns between year and day (inclusive), just like Pig syntax
select(flights, -(year:day)) # Select all columns except those from year to day (inclusive)
```

This function works similarly to the select argument to the base::subset().

###### Renaming
```{r}
select(flights, tail_num = tailnum) # only keep tail_num column
rename(flights, tail_num = tailnum) # keeps the whole df and doesn't drop any columns
```

##### Distinct
A common use of select() is to find out what values are set of variables takes. This is particularly useful in conjunction with the distinct() verb which only returns the unique values in a table.

```{r}
distinct(select(flights, tailnum)) # select all distinct flights
distinct(select(flights, origin, dest)) # select all distinct flight legs
```

This is very similar to base::unique() but should be much faster.

##### Mutate
As well as selecting from the set of existing columns, it's often useful to add new columns that are functions of existing columns. This is the job of `mutate()`.

```{r}
mutate(flights,
  gain = arr_delay - dep_delay,
  speed = distance / air_time * 60)
```

dplyr::mutate() works the same way as plyr::mutate() and similarly to base::transform(). The key difference between mutate() and transform() is that mutate allows you to refer to columns that you just created. See the vignette for a specific example.

If you only want to keep the new variables, use `transmute()`.

#### Sample
You can use sample_n() and sample_frac() to take a random sample of rows, either a fixed number for sample_n() or a fixed fraction for sample_frac().

```{r}
sample_n(flights, 10) # sample 10 rows
sample_frac(flights, 0.01) # sample 1% of the rows
```

Use `replace = TRUE` to perform a bootstrap sample.

#### Summarise with (group_by)
These verbs are useful, but they become really powerful when you combine them with the idea of “group by”, repeating the operation individually on groups of observations within the dataset. In dplyr, you use the `group_by()` function to describe how to break a dataset down into groups of rows. You can then use the resulting object in exactly the same functions as above; they'll automatically work “by group” when the input is a grouped.

```{r}
planes <- group_by(flights, tailnum)
delay <- summarise(planes,
		  count = n(),
		  dist = mean(distance, na.rm = TRUE),
		  delay = mean(arr_delay, na.rm = TRUE))
delay <- filter(delay, count > 20, dist < 2000)
```
Other aggregation function like `n()`: number of observations in the current group. `n_distinct(x)`: count then umber of unique values in x. `first(x)` (x[1]), `last(x)` (x[length(x)]), and `nth(x,n)` (x[n]) are very useful!

##### Roll-up
When you group by multiple variables, each summary peels off one level of the grouping. That makes it easy to progressively roll-up a dataset:

```{r}
daily <- group_by(flights, year, month, day)
per_day   <- summarise(daily, flights = n())
per_month <- summarise(per_day, flights = sum(flights))
per_year  <- summarise(per_month, flights = sum(flights))
```
It basically just aggregate in and out for you. However you need to be careful when progressively rolling up summaries like this: it's ok for sums and counts, but you need to think about weighting for means and variances, and it's not possible to do exactly for medians.

##### Chanining
he dplyr API is functional in the sense that function calls don't have side-effects, and you must always save their results. This doesn't lead to particularly elegant code if you want to do many operations at once. You either have to do it step-by-step.

```{r}
a1 <- group_by(flights, year, month, day)
a2 <- select(a1, arr_delay, dep_delay)
a3 <- summarise(a2,
		  arr = mean(arr_delay, na.rm = TRUE),
		  dep = mean(dep_delay, na.rm = TRUE))
a4 <- filter(a3, arr > 30 | dep > 30)
```

Or if you don't want to save the intermediate results, you need to wrap the function calls inside each other:

```{r}
filter(
  summarise(
    select(
      group_by(flights, year, month, day),
      arr_delay, dep_delay
    ),
    arr = mean(arr_delay, na.rm = TRUE),
    dep = mean(dep_delay, na.rm = TRUE)
  ),
  arr > 30 | dep > 30
)
```

This is difficult to read because the order of the operations is from inside to out, and the arguments are a long way away from the function. To get around this problem, dplyr provides the %>% operator. `x %>% f(y)` turns into `f(x, y)` so you can use it to rewrite multiple operations so you can read from left-to-right, top-to-bottom:

```{r}
flights %>%
  group_by(year, month, day) %>%
  select(arr_delay, dep_delay) %>%
  summarise(
    arr = mean(arr_delay, na.rm = TRUE),
    dep = mean(dep_delay, na.rm = TRUE)
  ) %>%
  filter(arr > 30 | dep > 30)
```

##### Other advantages of dplyr (vignettes are available)

* databases: as well as in memory data frames, dplyr also connects to databases. It allows you to work with remote, out-of-memory data, using exactly the same tools, because dplyr will translate your R code into the appropriate SQL.

* window-functions: a window function is a variation on an aggregation function. Where an aggregate function uses n inputs to produce 1 output, a window function uses n inputs to produce n outputs.

* `tbl_df` is this super handy wrapper around a data frame that won't accidentally print a lot of data to the screen. (No vignettes)

[github page]: https://github.com/hadley/dplyr
[vignette]: file:///Library/Frameworks/R.framework/Versions/3.1/Resources/library/dplyr/doc/introduction.html