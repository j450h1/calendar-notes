### Notes for Today

## Coursera Data Science Series: "Getting and Cleaning Data"

* **(Week 4) Editing Text Variables**: [slide](https://d396qusza40orc.cloudfront.net/getdata/lecture_slides/04_01_editingTextVariables.pdf)
	* **toupper(), tolower(), strsplit()**
	* **sub() & gsub()**: sub() only replace one instance, gsub replace all instances in that string
	* **grep() & grepl()**: 
		*grep("Alameda", county)* will give us the indices for reocrd where country = alameda
		*grep("Alameda", country, value = TRUE)* gives the actual values instead of the indices
		*grepl("Alameda", country)* returns a vector of TRUE/FALSE
	* **library(stringr)**: is very handy. Function such as nchar, substr, paste, paste0 (no space), and str_trim
	* **Variable names should be**:
		* All lower case when possible
		* Descriptive (Diagnosis v.s. Dx)
		* Not duplicated
		* Not have underscores, dots, or white spaces

* **(Week 4) Regular Experssion I/II: [slide1](https://d396qusza40orc.cloudfront.net/getdata/lecture_slides/04_02_regularExpressions.pdf) & [slide2](https://d396qusza40orc.cloudfront.net/getdata/lecture_slides/04_03_regularExpressionsII.pdf). This is the kind of lecture that you really need to see examples! Not just a summary.
	* Regular Expression can be thought of as a combination of *literals* and *metacharacters*
		* Literals form the words of the language
		* Metacharacters define the grammar

	* Metacharacters:
		* **^Begin**: express the beginning of a sentence
		* **end$**: express the end of a sentence
		* **[]**: represent a character class. can also use [^char1char2...], this means include everything but char1 and char2 in the character class
		* **|**: translate to OR, and we can include any number of alternatives. e.g. alt1 | alt2 | .... | alt10
		* **()**: subexpressions are often contained in parentheses to constrain the alternative. e.g. ^([Gg]ood)|[Bb]ad). () can also be used to 'remember' text matched by the subexpression, and the matched subexpression can be referred by \1, \2...etc.
		* **?**: the question mark indicates that the indicated expression is optional
		* **.**: refers to any character
		* ** * **: means 'any number, including none, of the item'
		* **+**: means at least one of the item
		* **{ and }**: referred to as interval qualifiers; this let us specify the minimum and maximum number of matches of an expression

	* If we often need to express a literal character that is a metacharacter, we need to escape them with \. e.g. (\.)

* **(Week 4) Working with Dates**: [slide](https://d396qusza40orc.cloudfront.net/getdata/lecture_slides/04_04_workingWithDates.pdf)
	* **Start simple**: d1=date() or d2=Sys.Date()
	* **Formatting dates**: %d = day as number (0-31), %a = abbreviated weekday, %A = unabbreviated weekday, %m = month(00-12), %b = abbreviated month, %B = unabbreviated month, %y = 2 digit year, %Y = four digit year
	* **Creating dates**: e.g. x = c("1jan1960"); z = as.Date(x, "%d%b%Y")
	* **Getting parts of a date**: In the base package, can use weekdays(d2), month(d2), julian(d2) to get Sunday, January, X days since 1970-01-01
	* **Lubridate**: a very handy package that handles date objects. e.g. *ymd("20140108"), mdy("08/04/2013"), dmy...etc.* We can also deal with times using *ymd_hms*. 
	* In lubridate, to get the date part, the syntax is slightly different. e.g. wday to get the day of the week

---

## Re-capping the notes from earlier week of Coursera "Getting and Cleaning Data"

* **Week 1**:
	* The goal of this course: Raw data -> Processing script -> Tidy Data -> Data analysis -> Data communication. We will focus on the first three steps, wheras traditional classes often only focus on the last two.
	* Describe components of getting to tidy data: The important thing is to have:
		* A code book describing each variable and its values in the tidy data set.
		* An explicit and exact recipe you used to go from raw data to tidy data, there is no parameter to the script.

	* [**Downloading files**](https://d396qusza40orc.cloudfront.net/getdata/lecture_slides/01_04_downLoadingFiles.pdf):
		* **setwd**: to set working directory
		* **file.exists & dir.create**: *if(!file.exists("data")) dir.create("data")* create a directory if it doesn't exist
		* **list.files()**: like the unix ls command
		* **download.file()**: with parameter fileUrl, destfile, method
	
	* [**Reading local files**](https://d396qusza40orc.cloudfront.net/getdata/lecture_slides/01_05_readingLocalFiles.pdf):
		* **read.table**: the default, flexible and robust. Reads the data into RAM - big data can cause problems.
		* **read.csv**: very similar to read.table, but the delimeter is assumed to be comma.
		* **Some more important parameters**: quote, na.strings, nrows, skip. In the instructor's experience, often quotation marks ' or " placed in data values cause troubles, setting quote="" resolves these.

	* [**Reading excel files**](https://d396qusza40orc.cloudfront.net/getdata/lecture_slides/01_06_readingExcelFiles.pdf):
		* **library(xlsx)**: can use read.xlsx to read .xlsx excel files
		* **read.xlsx**: with parameter *sheetIndex*, *colIndex*, *rowIndex*
		* **write.xlsx**: write into a excel file

	* [**Reading XML**](https://d396qusza40orc.cloudfront.net/getdata/lecture_slides/01_07_readingXML.pdf):
		* Extracting XML is the basis of web scraping, there are two components:
			* Markup - labels that give the text structure
			* Content - the actual text of the document
		* **Tags, elements, and attributes**: very similar to the same ideas in HTML
		* **Read an XML file into R**:
			* Use **xmlTreeParse** to load the doc, parameter useInternal=TRUE means we want to get all children nodes. Sometimes we would use **htmlTreeParse** to parse and load the doc.
			* Use **xmlRoot(doc)** to get the root note. At this point the whole doc is a huge list, and we can reference them using list syntax (or xmlSApply) or programmatically extract them (xpathSapply)
			* **XPath**: has its own syntax for extracting nodes that satisfy certain conditions
			* **xpathSapply**: can use to loop through specific node in the XML

	* [**Reading JSON**](https://d396qusza40orc.cloudfront.net/getdata/lecture_slides/01_08_readingJSON.pdf):
		* **library(jsonlite)**: use this pakcage to deal with JSON objects
		* **fromJSON**: to load JSON objects
		* **toJSON**: very handy if we need to write data frames to JSON
		* Check out the links in the end if you want to do more!

	* [**Data.table**]: We have already covered in 05312014.md

