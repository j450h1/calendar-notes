### Notes for Today

## Coursera Experiment Class

* **Week 4**:
	* [**The tradeoff when doing half fraction factorials**](https://d396qusza40orc.cloudfront.net/experiments/lecture_slides/Week4/EFI2014-Class-4A.pdf)
		
		* For experiment with k factors where each factor has two levels, we generally need to run 2^k experiments to test all the combinations, but this approach has its problems:
			
			* Running 2^k experiments for large k is costly and time consuming
			* Often the higher order interactions play little role in predicting y, so it might not be worth it to estimate them
		
		* In this section, we will learn how to reduce the number of experiments run, via the technique of 'half-fraction/fractional factorials'. Don't get intimidating by the name, all it means is that we are now only running a 'fractional' of the original 2^k experiments to approximate 'most of the information' you need to capture.
			
			* If we choose our runs in a smart way, then fractional factorials will collapse to full factorials if an effect is insignificant
			* One important lesson here is that by reducing the number of experiments run, we will reduce the cost of running of experiment, but our estimate might be in the wrong sign, wrong magnitude, and we don't get higher order term estimates, so in terms of the prediction might not be as good. That's the trade-off we have to keep in mind.

		* In the following sections we will talk about:

			* How to intelligently select the 'fractions' of experiment to run
			* Determine whether the degrading of prediction quality is worth it.

	* [**The technical details behind half-fractions**](https://d396qusza40orc.cloudfront.net/experiments/lecture_slides/Week4/EFI2014-Class-4B.pdf)

		* 'trade-off' table
		* Systematically run half-fractional experiment using the table
		* [**Crucial** concept]: When you run fractional experiment, you would soon realized some of your column variables in the design matrix are identical (e.g. column C is the same as column AB). This means that if the coefficient for the main effect C is large, you are never sure whether it is because main effect of C is large, or because the interaction AB is large --> This leads to 'confounding' (i.e. AB is confounding the effect of C)
		* This also means that when we try to solve the linear system, we have more variables than independent columns, so the system is under-determined. One way to solve this is to collapse the varaibles together, and estimate the coefficient of a square design matrix. (see lecture notes)
		* Read the treating water example!

	* [**All about disturbances, why we randomize, what covariate are**](https://d396qusza40orc.cloudfront.net/experiments/lecture_slides/Week4/EFI2014-Class-4C.pdf)

		* **Disturbance**: are uncontrolled and unmeasured variables
		* **covariate**: measured disturbances = variable which are measured, but not controlled = 'covariates'
		* The point of randomization is to make sure disturbance is not concenrated in one bucket
		